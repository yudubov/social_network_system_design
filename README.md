### System Design социальной сети для курса по System Design

### Первоаначальная постановка задачи
У бизнеса есть четкое понимание функциональности, которая эта социальная сеть должна будет предоставлять в будущем:

- публикация постов из путешествий с фотографиями, небольшим описанием и привязкой к конкретному месту путешествия;
- оценка и комментарии постов других путешественников;
- подписка на других путешественников, чтобы следить за их активностью;
- поиск популярных мест для путешествий и просмотр постов с этих мест;
- просмотр ленты других путешественников и ленты пользователя, основанной на подписках в обратном хронологическом порядке;

> Что касается будущей аудитории социальной сети - у бизнеса есть огромные средства для рекламы и продвижения социальной сети,
> поэтому пользовательская база будет постепенно линейно расти и предполагается,
> что через год достигнет примерно 10 000 000 уникальных пользователей в день, после чего также будет продолжать расти.
> Бизнес пока нацелен  только на аудиторию стран СНГ (*на зарубежный рынок выходить планов нет*).
> Будущая система должна быть очень надежной, а также, чтобы с ней было удобно взаимодействовать, используя мобильные устройства и браузер.

Исходя из всего этого, в этой части домашнем задания нужно:
- формализовать функциональные и нефункциональные требования к будущей системе, используя полученную информацию от бизнеса, анализ конкурентов и ваш собственный инженерный и пользовательский опыт. 
- после этого, нужно будет примерно оценить нагрузку (RPS и трафик) на будущую систему. 
- оценку нагрузки рекомендуется проводить в разрезе по подсистемам (посты, реакции, комментарии) вашей будущей системы.


### Функциональные требования 
• Назначение системы - социальная сеть для путешественников
• Требуется разработать веб-версию и мобильную версия системы
• Отчеты и аналитика не требуются
• Основные сущности системы, которыми управляет пользователь: пост, реакция, комментарий, подписки/отписки
• Просмотр постов пользователей доступен, в обратном хронологическом порядке 
• Система должна предоставлять возможность поиска популярных мест для путешествий. (фильтрация постов пользователей по справочникам стран, городов и выдача результатов)
• Система должна предоставлять полнотекстовый поиск по названиям и описаниям постов. 
• Основные сущности системы, которыми управляет пользователь: пост, реакция, комментарий, подписки/отписки
• Функции системы с основными сущностями:
1. (запись - постов) создание и публикация поста: 
- до 6 фотографий с максимальным размером 500Кб (допустимые форматы форматы - jpg, .png и .gif) 
- описание до 250 символов 
- указание в посте страны и города путешествия (выбор из заранее предпоготовленных справочников стран и городов)   
2. (чтение - постов) просмотр постов пользователя (своих), в обратном хронологическом порядке 
3. (чтение - постов) просмотр постов других пользователей, в обратном хронологическом порядке

4. (запись - комментарий) создание комментария до 500 символов
5. (чтение - комментарий) возможность ознакомления с комментариями других пользователей о постах пользователя

6. (запись - реакция) оценка поста другого пользователя
7. (чтение - реакция) просмотр оценок своих постов

8. (запись - подписка/отписка) возможность подписываться/отписывать от других пользователей
9. (чтение - подписка/отписка) возможность ознакамливаться со списком подписчиков пользователя



### Нефункциональные требования
• Сезонность - активность пользователей на 50% возрастает в летнее время
• Низкий сезон DAU 10 000 000 (зима, весна, осень)
• Высокий сезон DAU 15 000 000 (летнее время)
• Аудитория СНГ
• Условия хранения данных по постам: 
- данные давностью менее 1 года должны подгружаться в системе <=2 секунд
- данные давностью более 1 года должны подгружаться в системе <=5 секунд
• Уровень доступности системы - 99,9% времени (допускается 9 часов в год недоступности системы)
• Вся история постов пользователей, комментарии, реакции хранятся в системе и доступны к просмотру
• Активности пользователей
Посты:
1. (запись - пост) в среднем каждый пользователь публикует 1 пост в день
2. (чтение - постов) в среднем каждый пользователь просматривает ленту своих постов 1 раз в день, со средней глубиной просмотра 10 постов 
3. (чтение - постов) в среднем каждый пользователь просматривает 50 постов других пользователей в день

Комментарии:
4. (запись - комментарий) в среднем каждый пользователь пишет по 5 комментариев к другим постам в день
5. (чтение - комментарий) в среднем каждый пользователь просматривает 5 новых коментариев в день

Реакции:
6. (запись - реакция) в среднем каждый пользователь оценивает 50 постов других пользователей в день
7. (чтение - реакция) в среднем каждый пользователь ознкамливается с 10 новыми оценками своих постов в день

Подписки/отписки:
8. (запись - подписки) в среднем каждый пользователь подписывается на других пользователей, для отслеживания их активности 1 раз в день
9. (запись - отписки) в среднем каждый пользователь отписывается от других пользователей 0,2 раза в день
10. (чтение - подписки/отписки) в среднем каждый пользователь ознакамливается со списком своих подписчиков 2 раза в день

• Лимиты 
Пользователь может писать не более 500 комментариев в день к другим постам
Пользователь может публиковать не более 20 своих постов в день
Пользователь может просматривать не более 2000 постов других пользователей в день
Пользователь может оценивать не более 500 постов в день
Пользователь может подписывать не более чем на 500 других пользователей в день


### Оценка весов
• Оценка веса поста:
author_user_id - 20 байт
post_id - 20 байт
created_at - 10 байт
title - 100 байт
comment - 500 байт
city - 5 байт
country - 5 байт
foto - 3072000 байт
hashtag - 100 байт
Вес поста = 3072760 байт / округлим до 3Мб

• Оценка веса комментария:
author_user_id - 20 байт
commentator_user_id - 20 байт
post_id - 20 байт
created_at - 10 байт
comment - 1000 байт
Вес комментария = 1070 байт / округлим до 1 кб

• Оценка веса реакции:
author_user_id - 20 байт
commentator_user_id - 20 байт
post_id - 20 байт
created_at - 10 байт
estimate - 5 байт
Вес реакции = 80 байт / округлим до 100 байт 

• Оценка веса подписки/отписки:
user_id - 20 байт
subscriber_user_id - 20 байт
created_at - 10 байт
is_subscription - 5 байт
Вес подписки/отписки = 55 байт  



### Оценка RPS - низкого сезона (летний сезон +50%):
• RPS посты 
Пользователь публикует 1 пост в день
RPS – write = 10 000 000 * 1 / 100 000 = 100

Пользователь читает 10 своих постов и 50 постов других пользователей
RPS – read = 10 000 000 * 60 / 100 000 = 6 000


• RPS комментарии 
Пользователь пишет 5 комментариев в день
RPS – write = 10 000 000 * 5 / 100 000 = 500

Пользователь читает 5 комментариев в день
RPS – read = 10 000 000 * 5 / 100 000 = 500


• RPS реакции 
Пользователь оценивает 50 постов других пользователей в день
RPS – write = 10 000 000 * 50 / 100 000 = 5 000

Пользователь ознкамливается с 10 новыми оценками своих постов
RPS – read = 10 000 000 * 10 / 100 000 = 1 000


• RPS подписки/отписки 
Пользователь подписывает 1 раз в день и отписывается 0,2 раза в день
RPS – write = 10 000 000 * 1,2 / 100 000 = 120

Пользователь ознакамливается со списком своих подписчиков 2 раза в день
RPS – read = 10 000 000 * 2 / 100 000 = 200 


### Оценка трафика
• Traffic посты 
100 RPS весом:
Метаданные - 1 КБ
Traffic – write meta = 100 * 3 = 300 КБ/c

Медиафайлы - 3 Мб
Traffic – write media = 100 * 3 = 300 Мб/c


6000 RPS весом:
Метаданные - 1 КБ
Traffic – read meta = 6000 * 1 = 18 000 КБ/c

Медиафайлы - 3 Мб
Traffic – read media = 6000 * 3 = 18 000 Mб/c


• Traffic комментарии 
500 RPS весом 1 кб 
Traffic – write = 500 * 1 = 500 кб/c

500 RPS весом 1 кб 
Traffic – read = 500 * 1 = 500 кб/c 


• Traffic реакции 
5 000 RPS весом 100 байт
Traffic – write = 5 000 * 100 = 500 000 байт/c - округлим до 500 кб/c  

1 000 RPS весом 100 байт
Traffic – read = 1 000 * 100 = 100 000 байт/c - округлим до 100 кб/c  


• Traffic подписки/отписки 
120 RPS весом 55 байт 
Traffic – write = 120 * 55 = 6 600 байт/c - округлим до 7 кб/c 

200 RPS весом 55 байт  
Traffic – read = 200 * 55 = 11 000 байт/c - округлим до 11 кб/c 


### Расчет одновременных соединений - низкого сезона (летнее сезон +50%):
Connections = 10 000 000 * 0.1 = 1 000 000 


### Вывод: 
Самая большая операция по RPS и трафику: чтение постов (6000 RPS, 18 000 Mб/c)
Приложение заточено больше на операцию чтение 


### API (псевдокод)
Посты:
• Создание поста - CreatePost(params) 
• Загрузка фотографий в пост - UploadPhotos(params)
• Чтение постов - ListPosts(params) 

Комментарии:
• Создание комментария поста - CreateComment(params) 
• Чтение комментариев постов - ListComments(params) 

Реакции оценки:
• Создание оценки поста - CreateRating(params) 
• Чтение оценок постов - ListRatings(params) 

Реакции подписки/отписки:
• Создание подписки/отписки на пользователя - CreateSubscription(params) 
• Чтение подписок/отписок пользователя - ListSubscriptions(params)


### Capacity (вместимость хранения данных в год с учетом сезонов):

• Capacity посты
Посты meta - низкий сезон = 300 КБ/c (Traffic – write) * 86400 (секунд в дне) * 275 (дней) = 7 128 000 000 КБ = 7 ТБ 
Посты meta - высокий сезон (лето) = 600 КБ/c * 86400 * 90 = 4 665 600 000 КБ = 5 ТБ
Итого meta посты в год = 12 ТБ

Посты media низкий сезон = 300 Мб/c * 86400 * 275 = 7 128 000 000 МБ = 7 ПБ
Посты media высокий сезон (лето) = 600 Мб/c * 86400 * 90 = 4 665 600 000 = 5 ПБ
Итого media посты в год = 12 ПБ


• Capacity комментарии 
Комментарии - низкий сезон = 500 КБ/c * 86400 * 275 = 11 880 000 000 КБ = 12 ТБ 
Комментарии - высокий сезон (лето) = 1 000 КБ/c * 86400 * 90 = 7 776 000 000 КБ = 8 ТБ 
Итого комментарии в год = 20 ТБ


• Capacity реакции (оценки)
Реакции - низкий сезон = 500 КБ/c * 86400 * 275 = 11 880 000 000 КБ = 12 ТБ 
Реакции - высокий сезон (лето) = 1 000 КБ/c * 86400 * 90 = 7 776 000 000 КБ = 8 ТБ 
Итого реакции в год = 20 ТБ


• Capacity подписки/отписки  
Подписки/отписки - низкий сезон = 7 КБ/c * 86400 * 275 = 166 320 000 КБ = 0,2 ТБ 
Подписки/отписки  - высокий сезон (лето) = 14 КБ/c * 86400 * 90 = 108 864 000 КБ = 0,1 ТБ 
Итого подписки/отписки  в год = 0,3 ТБ


### Расчет HDD/SSD жестких дисков

Disks_for_capacity = объем данных, которое необходимо хранить / объем одного диска 
Disks_for_throughput = суммарный трафик на запись/чтение в секунду  / пропускная способность одного диска 
Disks_for_iops = RPS суммарный на запись и чтение  / количество операций ввода-вывод диска в секунду 
Disks = максимальное кол-во дисков из всех расчетов


### PostgreSQL расчеты по подсистемам 

### Комментарии расчет жестких дисков
HDD
1. Disks_for_capacity = 20 Тб / 32 Тб = 0,6 = 1 диск (округляем до 1 диска)
2. Disks_for_throughput = 1000 кб/c (или 1 Мб/c) / 100 Mb/s = 0,01 = 1 диск (округляем до 1)
3. Disks_for_iops = 1000 / 100 = 10 дисков
4. Disks = max(1, 1, 10) = 10 
10 дисков HHD по 32 ТБ

SSD (SATA)
1. Disks_for_capacity = 20 Тб / 28 Тб = 0,6 = 1 диск (округляем до 1 диска)
2. Disks_for_throughput = 1000 кб/c (или 1 Мб/c) / 500 Mb/s = 0,002 = 1 диск (округляем до 1)
3. Disks_for_iops = 1000 / 1000 = 1 диск
4. Disks = max(1, 1, 1) = 1
1 диск SSD 28 ТБ
• Для комментарие выбираем 1 диск SSD 28 ТБ - дороже, но простая конфигурация



### Подписки/отписки расчет жестких дисков
HDD
1. Disks_for_capacity = 0,3 Тб / 1 Тб = 0,3 = 1 диск (округляем до 1 диска)
2. Disks_for_throughput = 14 кб/c (или 0,004 Мб/c) / 100 Мб/c = 0,00014 = 1 диск (округляем до 1)
3. Disks_for_iops = 320 / 100 = 3,2 = 4 диска (округляем до 4 дисков)
4. Disks = max(1, 1, 4) = 4 диска
4 диска HHD по 2 ТБ

SSD (SATA)
1. Disks_for_capacity = 20 Тб / 1 Тб = 0,3 = 1 диск (округляем до 1 диска)
2. Disks_for_throughput = 4 кб/c (или 0,004 Мб/c) / 500 Мб/c = 0,002 = 1 диск (округляем до 1)
3. Disks_for_iops = 320 / 1000 = 0,32 = 1 диск (округляем до 1 диска)
4. Disks = max(1, 1, 1) = 1
1 диск SSD 1 ТБ
• Для подписок/отписок выбираем 1 диск SSD 1 ТБ - дороже, но простая конфигурация


###  Реакции расчет жестких дисков
HDD
1. Disks_for_capacity = 20 Тб / 4 Тб = 5 дисков
2. Disks_for_throughput = 600 кб/c (или 0,6 Мб/c) / 100 Мб/c = 0,006 = 1 диск (округляем до 1)
3. Disks_for_iops = 6000 / 100 = 60 дисков
4. Disks = max(5, 1, 60) = 60
60 дисков HHD по 2 ТБ

SSD (SATA)
1. Disks_for_capacity = 20 Тб / 4 Тб = 6 дисков
2. Disks_for_throughput = 600 кб/c (или 0,6 Мб/c) / 500 Мб/c = 0,0012 = 1 диск (округляем до 1)
3. Disks_for_iops = 6000 / 1000 = 6 дисков
4. Disks = max(6, 1, 6) = 6
6 дисков SSD по 4 ТБ

60 дисков HHD или 6 дисков SSD при этом трафик средний и высокий RPS. Дополнительно рассчитаем SSD (nVME).

SSD (nVME)
1. Disks_for_capacity = 20 Тб / 28 Тб = 1 диск
2. Disks_for_throughput = 600 кб/c (или 0,6 Мб/c) / 3 Гб/c = 1 диск (округляем до 1)
3. Disks_for_iops = 6000 / 10 000 = 1 диск
4. Disks = max(1, 1, 1) = 1
1 диск SSD (nVME) 28 ТБ
• Для реакций выбираем 1 диск SSD (nVME) 28 ТБ - из-за большого количества RPS SSD (nVME) идеально и оптимально подходит, реализация  дороже, но простая конфигурация


### Посты META расчет жестких дисков
HDD
1. Disks_for_capacity = 12 Тб / 1 Тб = 12 дисков
2. Disks_for_throughput = 18 000 КБ/c (или 18 Мб/c) / 100 Мб/c = 0,18 = 1 диск (округляем до 1)
3. Disks_for_iops = 6100 / 100 = 61 диск
4. Disks = max(12, 1, 61) = 61 диск
61 диск HHD по 1 ТБ

SSD (SATA)
1. Disks_for_capacity = 12 Тб / 3 Тб = 4 диска
2. Disks_for_throughput = 18 000 КБ/c (или 18 Мб/c) / 500 Мб/c = 0,036 = 1 диск (округляем до 1)
3. Disks_for_iops = 6100 / 1000 = 6,1 = 7 дисков (округляем до 1 диска)
4. Disks = max(4, 1, 7) = 7
7 дисков SSD по 3 ТБ

61 диск HHD или 7 дисков SSD при этом трафик средний и высокий RPS. Дополнительно рассчитаем SSD (nVME).

SSD (nVME)
1. Disks_for_capacity = 12 Тб / 18 Тб = 1 диск
2. Disks_for_throughput = 18 000 КБ/c (или 18 Мб/c) / 3 Гб/c = 1 диск (округляем до 1)
3. Disks_for_iops = 6100 / 10 000 = 1 диск
4. Disks = max(1, 1, 6) = 1
1 диск SSD (nVME) 18 ТБ
• Для постов meta выбираем 1 диск SSD (nVME) 18 ТБ - из-за большого количества RPS SSD (nVME) идеально и оптимально подходит, реализация  дороже, но простая конфигурация.


### Хранилище S3 для media:
Исходные вводные:
capacity = 12 Пб (очень много, требуется оптимизация хранения)
traffic_per_second = 18 000 Мб/c
iops = 6100 

Оптимизация:
1. Media данные постов (фото) будут храниться в бакете Selectel S3.
У Selectel S3 есть алгоритм сжатия Image Stack - позволяет уменьшить размер фото до 25–35%. 
Поддерживает форматы - jpg, .png и .gif (добавлю в ФТ)
Не могу найти сколько CPU тратится на сжатие фото. Но это и не пригодится)) Переносить из SSD на HHD и сжимать будем в ночное время, асинхронно, когда нагрузка спадает. 
2. Охлаждение 
2.1 Свежие данные храним на SSD - посты давностью до 2 месяцев = 12ПБ /12 месяцев = 2 ПБ (не сжимаем)
2.2 Старые данные храним на HHD (к которым реже обращаются) - посты давностью более 2 месяцев = 10 Пб
Старые данные - 10 Пб дополнительно сжимаем в S3 и уменьшаем объем до 7,5Пб


###  Посты MEDIA расчет жестких дисков - для свежих данных 2ПБ
SSD (SATA) 
1. Disks_for_capacity = 2 ПБ (2000 ТБ)/ 68 Тб = 29 дисков
2. Disks_for_throughput = 18 000 Мб/c / 500 Мб/c = 36 дисков
3. Disks_for_iops = 6100 / 1000 = 6,1 = 7 дисков (округляем до 1 диска)
4. Disks = max(29, 36, 7) = 36
36 дисков SSD по 68 ТБ

HDD
1. Disks_for_capacity = 2 Пб ( 2 000 Тб) / 32 Тб = 63 диска
2. Disks_for_throughput = 18 000 Мб/c / 100 Мб/c = 180 дисков 
3. Disks_for_iops = 6100 / 100 = 61 диск
4. Disks = max(75, 180, 61) = 61 диск
180 дисков HHD по 32 ТБ
• Для СВЕЖИХ постов MEDIA выбираем 180 дисков HHD 32 ТБ. (Конфигурация с 36 дисками SSD по 68 ТБ значительно дороже)

### Посты MEDIA расчет жестких дисков - для архивного хранения данных 7,5 ПБ в сжатом виде
HDD будет очень много дисков из-за большого объема хранения, будет сложная конфигурация, но данные имеют второстепенный приоритет, к данным обращаются реже и риски ниже. 

HDD
1. Disks_for_capacity = 7,5 ПБ (7 500 ТБ) / 32 Тб = 280 дисков (c запасом 20%)
2. Disks_for_throughput = 18 000 Мб/c / 100 Мб/c = 180 дисков 
3. Disks_for_iops = 6100 / 100 = 61 диск
4. Disks = max(280, 180, 61) = 280 дисков
• Для СТАРЫХ постов MEDIA выбираем 280 дисков HHD по 32 ТБ
• Для поддержания IOPS требуется 180 дисков, а у нас будет 280 дисков. 100 дисков запаса точно покроют CPU операциий на разжатие. 


• Redis: 
Redis синхронизируется и кэширует ЧАСТЬ данных из PostgreSQL для ускорения выдачи постов золотых блогеров.
Хранится N последних постов золотых блогеров. N - настраивается конфигурацией. Золотой блогер определяется по признаку users.is_popular_blogger 
Реализован процесс, который через скрипты прогревает кэш. В случае перезагрузки сервиса, кэш атвоматически наполняется.
Алгоритм вытеснеия данных - FIFO
Метаданные 1 поста = 1 КБ
Для Redis выделяется 1 хост - RAM 512 Гб
50% ресурсов RAM выделяется на работу хоста и синхронизацию с PostgreSQL = 256 Гб 
50% ресурсов RAM выделяется на хранение кэша по постам золотых блогеров = 256 Гб 
картинки постов не кэшируются и подтягиваются с S3 при загрузке
(HDD) 1 диск 2 ТБ


• ClickHouse
СlickHouse синхронизируется и дублирует данные из PostgreSQL для сложный аналитических запросов. 
Требуется выделить аналогичный объем для данных по подсистемам, как и для PostgreSQL. 


• Elasticsearch
Elasticsearch синхронизируется и дублирует данные из PostgreSQL для полнотекстового поиска. 
Промежуточный сервис определяет тип запроса (точный по id записи или текстовый) и направляет его в PostgreSQL или Elasticsearch.
Если текстовый запрос -> Elasticsearch находит максимально подходящие записи по релевантности -> направляет id записей в PostgreSQL -> PostgreSQL формирует набор записей для ответа по релевантнсотси 
Требуется выделить аналогичный объем для данных по подсистемам, как и для PostgreSQL.


### Репликация и шардирование 

### Репликация и шардирование PostgreSQL
- асинхронная репликация (не требуется строгая согласованность, а в приоритете высокая скорость)
- RF (Replication Factor) - 2 (ресурсы ограничены)
- репликация master-slave (пишем в master, читаем из master и slave) нет требований по доступности из нескольких дата-центров
- принцип шардирования подсистем - по user_id все данные пользователя хранятся на одном хосте
- забыл описать таблицы "стран" и "городов" в предыдущем задании - эти таблицы справочные и в полном объеме переносятся в каждый шард. 
- картинки постов подтягиваются с S3 при загрузке


### Репликация и шардирование хранилища S3
•  Посты media
- асинхронная репликация (не требуется строгая согласованность, а в приоритете высокая скорость)
- RF (Replication Factor) - 2 (ресурсы ограничены)
- репликация master-slave (пишем в master, читаем из master и slave) нет требований по доступности из нескольких дата-центров
- принцип шардирования подсистем - по post_id все фото поста хранятся на одном хосте


### Репликация и шардирование Redis
• Посты золотых блогеров
- не требуется репликация. Реализован процесс, который через скрипты прогревает кэш. В случае перезагрузки сервиса, кэш атвоматически наполняется.
- Redis синхронизируется и хэширует ЧАСТЬ данных из PostgreSQL для ускорения выдачи постов золотых блогеров.
- Хранится N последних постов золотых блогеров. N - настраивается конфигурацией. 
- Золотой блогер определяется по количеству подписчиков.
- Алгоритм вытеснеия данных - FIFO


### Репликация и шардирование ClickHouse
• СlickHouse синхронизируется и дублирует данные из PostgreSQL для сложный аналитических запросов. 
- асинхронная репликация (используется по умолчанию в ClickHouse) - не требуется строгая согласованность, а в приоритете высокая скорость 
- RF (Replication Factor) - 2 (ресурсы ограничены)
- ClickHouse поддерживает репликацию и шардирование, только master-master (выбирать не приходится)
- картинки постов подтягиваются с S3 при загрузке (например, если аналитику (или ML) необходимо проанализировать самые популярные фото в постах)


### Репликация и шардирование Elasticsearch
• Elasticsearch синхронизируется и дублирует данные из PostgreSQL для полнотекстового поиска. 
- асинхронная репликация (не требуется строгая согласованность, а в приоритете высокая скорость) 
- Elasticsearch поддерживает репликацию и шардирование, только master-slave (выбирать не приходится). Но master не работает с данными, а работает, как координатор и является точкой отказа для всего кластера.
- RF (Replication Factor) - 2 для slave (ресурсы ограничены), 3 для master (координатор) 


## Хосты по подсистемам PostgreSQL
• Комментарии
1 диск SSD 28 ТБ
- 1 диск на хост => RF-2 - 1 хост * 2 = 2 хоста
Итого: 2 хоста и шардирование не требуется

• Подписки/отписки
1 диск SSD 1 ТБ
- 1 диск на хост => RF-2 - 1 хост * 2 = 2 хоста
Итого: 2 хоста и шардирование не требуется

• Реакции 
1 диск SSD (nVME) 28 ТБ
- 1 диск на хост => RF-2 - 1 хост * 2 = 2 хоста
Итого: 2 хоста и шардирование не требуется

•  Посты meta
1 диск SSD (nVME) 18 ТБ
- 1 диск на хост => RF-2 - 1 хост * 2 = 2 хоста
Итого: 2 хоста и шардирование не требуется

В целом шардирование PostgreSQL не требуется. 


### Хосты для хранилища S3
• Хосты для СВЕЖИХ постов MEDIA
180 дисков HHD 32 ТБ
- по 2 диска на 1 хост => 90 хостов => если 90 хостов, то потребуется разнести на 90 шардов => RF-2 - 90 хостов * 2 = 180 хостов 
Итого: 180 хостов по 2 диска

• Хосты СТАРЫХ постов MEDIA
280 дисков HHD по 32 ТБ
- по 2 диска на 1 хост => 140 хостов => если 140 хостов, то потребуется разнести на 140 шардов => RF-2 - 140 хостов * 2 = 280 хоста
Итого: 280 хостов по 2 диска


## Хосты для постов золотых блогеров Redis (1 пост = 1 КБ)
(HDD) 1 диск 2 ТБ
1 хост с RAM 512 Гб
Не требуется репликация и шардирование. 
Реализован процесс, который через скрипты прогревает кэш. 
В случае перезагрузки сервиса, кэш атвоматически наполняется.


### Хосты для ClickHouse
• СlickHouse синхронизируется и дублирует данные из PostgreSQL для сложный аналитических запросов. 
Требуется выделить аналогичный объем хостов и шардов для подсистемам, как и в PostgreSQL. 



### Репликация и шардирование Elasticsearch
• Elasticsearch синхронизируется и дублирует данные из PostgreSQL для полнотекстового поиска. 
Требуется выделить аналогичный объем хостов и шардов для подсистемам, как и в PostgreSQL. 
И для каждой подсистемы дополнительно по 3 хоста для master.
